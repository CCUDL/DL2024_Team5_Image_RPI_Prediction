{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df29fa17-5a32-4bab-8bf7-310d66c57909",
   "metadata": {
    "id": "df29fa17-5a32-4bab-8bf7-310d66c57909",
    "outputId": "14abfdcf-0a5c-4cbd-d49b-ce750feea842"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential, layers, Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.initializers import RandomNormal, HeNormal, GlorotNormal\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a183989-9dc9-4b81-9fdb-598b6f2fbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#溶氧量點數\n",
    "def DO_value(num):\n",
    "  if (num >= 6.5):\n",
    "    return 1\n",
    "  elif(num >= 4.6):\n",
    "    return 3\n",
    "  elif(num >= 2.0):\n",
    "    return 6\n",
    "  else:\n",
    "    return 10\n",
    "\n",
    "#懸浮固體點數\n",
    "def TSS_value(num):\n",
    "  if (num <= 20.0):\n",
    "    return 1\n",
    "  elif(num <= 49.9):\n",
    "    return 3\n",
    "  elif(num <= 100):\n",
    "    return 6\n",
    "  else:\n",
    "    return 10\n",
    "\n",
    "#生化需氧量點數\n",
    "def BOD_value(num):\n",
    "  if (num <= 3.0):\n",
    "    return 1\n",
    "  elif(num <= 4.9):\n",
    "    return 3\n",
    "  elif(num <= 15.0):\n",
    "    return 6\n",
    "  else:\n",
    "    return 10\n",
    "\n",
    "#氨氣點數\n",
    "def NH3N_value(num):\n",
    "  if (num <= 0.5):\n",
    "    return 1\n",
    "  elif(num <= 0.99):\n",
    "    return 3\n",
    "  elif(num <= 3.0):\n",
    "    return 6\n",
    "  else:\n",
    "    return 10\n",
    "\n",
    "#計算RPI(River Pollution Index)\n",
    "def cal_RPI(DO, TSS, BOD, NH3N):\n",
    "  DO_num = DO_value(DO)\n",
    "  TSS_num = TSS_value(TSS)\n",
    "  BOD_num = BOD_value(BOD)\n",
    "  NH3N_num = NH3N_value(NH3N)\n",
    "  return (DO_num + TSS_num + BOD_num + NH3N_num)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe2437e-a4af-4318-96b0-dddba084cde6",
   "metadata": {
    "id": "bbe2437e-a4af-4318-96b0-dddba084cde6"
   },
   "outputs": [],
   "source": [
    "# RPI = (DO + SS + BOD + NH3N) / 4\n",
    "# NH3-N / NO3-N = K  -->  NH3-N = NO3-N * K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bc81a9-8139-4a24-9dac-3aa6b5f37255",
   "metadata": {
    "id": "68bc81a9-8139-4a24-9dac-3aa6b5f37255"
   },
   "outputs": [],
   "source": [
    "# def cal_RPI(DO, SS, BOD, NH3N):\n",
    "#     return (DO + SS + BOD + NH3N) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea27c056-bc25-4afa-97f4-a1553827c33c",
   "metadata": {
    "id": "ea27c056-bc25-4afa-97f4-a1553827c33c"
   },
   "outputs": [],
   "source": [
    "APRIL_RPI = cal_RPI(9.0 ,15, 0 ,1.3/4.5)\n",
    "MAY_RPI = cal_RPI(8.4, 10, 0, 2.5/4.5)\n",
    "JUNE_RPI = cal_RPI(8.5, 16, 0, 1.7/4.5)\n",
    "JULY_RPI = cal_RPI(6.4, 24, 0, 2.6/4.5)\n",
    "AUGUST_RPI = cal_RPI(8.1, 143, 0, 1.2/4.5)\n",
    "SEPTEMBER_RPI = cal_RPI(7.7, 53, 0, 1.5/4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30aeb04e-2848-48be-8cf8-d089dd47956b",
   "metadata": {
    "id": "30aeb04e-2848-48be-8cf8-d089dd47956b",
    "outputId": "060f1062-58f0-4603-ab0b-fdbdbe66bf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April RPI: 1.0\n",
      "May RPI: 1.5\n",
      "June RPI: 1.0\n",
      "July RPI: 2.5\n",
      "August RPI: 3.25\n",
      "September RPI: 2.25\n"
     ]
    }
   ],
   "source": [
    "# Printing the calculated values\n",
    "print(\"April RPI:\", APRIL_RPI)\n",
    "print(\"May RPI:\", MAY_RPI)\n",
    "print(\"June RPI:\", JUNE_RPI)\n",
    "print(\"July RPI:\", JULY_RPI)\n",
    "print(\"August RPI:\", AUGUST_RPI)\n",
    "print(\"September RPI:\", SEPTEMBER_RPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cee9eb-68ea-447a-b9db-3cfc0be1d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(val):\n",
    "    if val <= 2.0:\n",
    "        return \"A\"\n",
    "    elif val <= 3.0:\n",
    "        return \"B\"\n",
    "    elif val <= 6.0:\n",
    "        return \"C\"\n",
    "    else:\n",
    "        return \"D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031f260f-5929-4d6b-8e6e-adcd3699c6fa",
   "metadata": {
    "id": "031f260f-5929-4d6b-8e6e-adcd3699c6fa"
   },
   "outputs": [],
   "source": [
    "folder_paths = ['./水質檢測/Image_data/1_April',\n",
    "                './水質檢測/Image_data/2_May',\n",
    "                './水質檢測/Image_data/3_June',\n",
    "                './水質檢測/Image_data/4_July',\n",
    "                './水質檢測/Image_data/5_August',\n",
    "                './水質檢測/Image_data/6_September']\n",
    "labels = [get_label(APRIL_RPI), get_label(MAY_RPI), get_label(JUNE_RPI), \n",
    "          get_label(JULY_RPI), get_label(AUGUST_RPI), get_label(SEPTEMBER_RPI)]  # 对应文件夹1和文件夹2的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e666a5-c933-4693-917e-ae6851d0ab52",
   "metadata": {
    "id": "09e666a5-c933-4693-917e-ae6851d0ab52"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def load_and_label_images(folder_path, label):\n",
    "    image_paths = []  # 存储图像文件的路径\n",
    "    labels = []       # 存储图像对应的标签\n",
    "\n",
    "    # 获取文件夹中的所有图像文件的路径\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # 假设只加载jpg和png格式的图像文件\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "            labels.append(label)\n",
    "\n",
    "    # 加载图像并为其指定标签\n",
    "    images = [tf.io.read_file(image_path) for image_path in image_paths]\n",
    "    images = [tf.image.decode_image(image, channels=3) for image in images]\n",
    "\n",
    "    # 可选的数据预处理：这里假设对图像进行归一化\n",
    "    #images = [tf.cast(image, tf.float32) / 255.0 for image in images]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1275d6-df3d-4313-bc65-ea41b554f30b",
   "metadata": {
    "id": "9c1275d6-df3d-4313-bc65-ea41b554f30b"
   },
   "outputs": [],
   "source": [
    "# 你可以根据需要加载多个文件夹中的图像并为其指定不同的标签\n",
    "# folder_paths = ['/path/to/folder1', '/path/to/folder2']\n",
    "# labels = [1, 2]  # 对应文件夹1和文件夹2的标签\n",
    "\n",
    "# 加载所有文件夹中的图像和标签\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for folder_path, label in zip(folder_paths, labels):\n",
    "    images, labels = load_and_label_images(folder_path, label)\n",
    "    all_images.extend(images)\n",
    "    all_labels.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb56706-c873-4e3e-af24-a6db9109ea4e",
   "metadata": {
    "id": "afb56706-c873-4e3e-af24-a6db9109ea4e"
   },
   "outputs": [],
   "source": [
    "unique_labels_list = list(set(all_labels))\n",
    "unique_labels_list.sort()\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels_list)}\n",
    "label_one_hot = [tf.one_hot(label_to_index[label], len(unique_labels_list)) for label in all_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f916f3f2-2c54-44fb-ab38-686d39e25d5a",
   "metadata": {
    "id": "f916f3f2-2c54-44fb-ab38-686d39e25d5a",
    "outputId": "8d52d023-5f1d-4c2c-8ab7-a31566b0a06d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9728\n",
      "(224, 224, 3)\n",
      "9728\n",
      "[<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_images))\n",
    "print(all_images[0].shape)\n",
    "\n",
    "print(len(label_one_hot))\n",
    "print(label_one_hot[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c62937c-f7ff-4f53-aa11-fe829587d15b",
   "metadata": {
    "id": "8c62937c-f7ff-4f53-aa11-fe829587d15b"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_images, validation_images, train_labels, validation_labels = train_test_split(all_images, label_one_hot, test_size=0.2, random_state=42)\n",
    "# 创建训练集数据集\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size=32)\n",
    "\n",
    "# 创建验证集数据集\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "validation_dataset = validation_dataset.batch(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a64943b7-3d2b-4b80-b0cc-e4e0db1f458e",
   "metadata": {
    "id": "a64943b7-3d2b-4b80-b0cc-e4e0db1f458e"
   },
   "outputs": [],
   "source": [
    "# # 构建数据集\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((all_images, label_one_hot))\n",
    "\n",
    "# # 可选的打乱和分批处理\n",
    "# dataset = dataset.shuffle(buffer_size=len(all_images)).batch(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee37a14c-20d5-4284-a915-218a5556fdd0",
   "metadata": {
    "id": "ee37a14c-20d5-4284-a915-218a5556fdd0",
    "outputId": "189ac0ae-1c52-4ea7-a218-08e95b8a2bc1"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 从数据集中获取并显示图像\n",
    "# fig, axs = plt.subplots(2, 5, figsize=(20, 8))  # 创建一个2x5的子图布局\n",
    "\n",
    "# for i, (image, label) in enumerate(dataset.take(10)):  # 取出前十张图像\n",
    "#     row = i // 5  # 计算当前图像应该位于的行索引\n",
    "#     col = i % 5   # 计算当前图像应该位于的列索引\n",
    "\n",
    "#     axs[row, col].imshow(image[0])  # 假设每个batch里只有一张图像\n",
    "#     axs[row, col].set_title('Label: {}'.format(label[0].numpy()))\n",
    "#     axs[row, col].axis('off')  # 关闭坐标轴\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11fadea-067a-41f5-93f3-e1dd204bbf40",
   "metadata": {
    "id": "d11fadea-067a-41f5-93f3-e1dd204bbf40"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 定义一个简单的卷积神经网络模型\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # tf.keras.layers.Dropout(0.1),  # 添加 Dropout 層，丟棄 25% 的神經元\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # tf.keras.layers.Dropout(0.1),  # 添加 Dropout 層，丟棄 25% 的神經元\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # tf.keras.layers.Dropout(0.2),   # 添加 Dropout 層，丟棄 50% 的神經元\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "318dd38c-5f37-4242-992d-057dacd8da05",
   "metadata": {
    "id": "318dd38c-5f37-4242-992d-057dacd8da05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/future-outlier/miniconda3/envs/dev/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3708dceb-452d-4180-bdef-45468222aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.keras',  # 保存模型的文件路径\n",
    "    monitor='val_accuracy',    # 监控的指标，可以是'val_loss'或'val_accuracy'\n",
    "    save_best_only=True,       # 仅保存最好的模型\n",
    "    mode='max',                # 对于准确率，使用'max'模式\n",
    "    verbose=1                  # 输出详细日志信息\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb945a98-1fc8-4c0e-bc09-5fa2171e459d",
   "metadata": {
    "id": "bb945a98-1fc8-4c0e-bc09-5fa2171e459d",
    "outputId": "11fa26b6-c422-466a-e69f-321ed66f8461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.5344 - loss: 27.8166\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99538, saving model to best_model.keras\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 214ms/step - accuracy: 0.5349 - loss: 27.7301 - val_accuracy: 0.9954 - val_loss: 0.0282\n",
      "Epoch 2/5\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9944 - loss: 0.0353\n",
      "Epoch 2: val_accuracy improved from 0.99538 to 0.99846, saving model to best_model.keras\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 216ms/step - accuracy: 0.9944 - loss: 0.0353 - val_accuracy: 0.9985 - val_loss: 0.0038\n",
      "Epoch 3/5\n",
      "\u001b[1m243/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9975 - loss: 0.0166\n",
      "Epoch 3: val_accuracy did not improve from 0.99846\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 215ms/step - accuracy: 0.9975 - loss: 0.0166 - val_accuracy: 0.9985 - val_loss: 0.0046\n",
      "Epoch 4/5\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9998 - loss: 0.0013\n",
      "Epoch 4: val_accuracy did not improve from 0.99846\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 215ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9969 - val_loss: 0.0157\n",
      "Epoch 5/5\n",
      "\u001b[1m 87/244\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 203ms/step - accuracy: 0.9848 - loss: 0.0568"
     ]
    }
   ],
   "source": [
    "# 這裡建議把epoch設小一點\n",
    "# 我跑的時候差不多一個epoch要5~7分鐘\n",
    "\n",
    "result = model.fit(train_dataset, \n",
    "                   validation_data=validation_dataset, \n",
    "                   epochs=5,verbose=1, \n",
    "                   callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06465f2b-9774-4fc1-8257-070ecebde2b4",
   "metadata": {
    "id": "06465f2b-9774-4fc1-8257-070ecebde2b4",
    "outputId": "750dd20a-5bcd-4cab-f81d-c5fe127af6f4"
   },
   "outputs": [],
   "source": [
    "plt.plot(result.history['accuracy'], label='accuracy')\n",
    "plt.plot(result.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81bd23-cd48-45a9-bdaf-a632cb19c23c",
   "metadata": {
    "id": "0b81bd23-cd48-45a9-bdaf-a632cb19c23c"
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd48e60-4a6e-46cb-967e-f5bdb9a610ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6aa3f-295a-4ba5-a917-3bfdaffbbc52",
   "metadata": {
    "id": "c6c6aa3f-295a-4ba5-a917-3bfdaffbbc52"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 使用model預測\n",
    "predictions = model.predict(validation_dataset)\n",
    "# 轉換成class index\n",
    "predicted_classes_index = np.argmax(predictions, axis=1)\n",
    "true_classes_index = np.argmax([label.numpy() for label in validation_labels], axis=1)\n",
    "\n",
    "# 計算confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes_index, predicted_classes_index)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iv_0o-93lQra",
   "metadata": {
    "id": "iv_0o-93lQra"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(validation_labels)\n",
    "print(predictions.shape, true_labels.shape)\n",
    "\n",
    "# 計算AUCROC\n",
    "aucroc = roc_auc_score(true_labels, predictions, average='macro', multi_class='ovo')\n",
    "print(\"AUCROC:\", aucroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fada5d-efcd-40bc-80b3-ea3985ad6397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35fcf9-11b9-4a00-8fb2-d71debaa2758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
