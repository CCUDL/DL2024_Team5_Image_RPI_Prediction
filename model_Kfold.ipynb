{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df29fa17-5a32-4bab-8bf7-310d66c57909",
   "metadata": {
    "id": "df29fa17-5a32-4bab-8bf7-310d66c57909",
    "outputId": "14abfdcf-0a5c-4cbd-d49b-ce750feea842"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential, layers, Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.initializers import RandomNormal, HeNormal, GlorotNormal\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a183989-9dc9-4b81-9fdb-598b6f2fbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#溶氧量點數\n",
    "def DO_value(num):\n",
    "  if (num >= 6.5):\n",
    "    return 1\n",
    "  elif(num >= 4.6):\n",
    "    return 3\n",
    "  elif(num >= 2.0):\n",
    "    return 6\n",
    "  else:\n",
    "    return 10\n",
    "\n",
    "#懸浮固體點數\n",
    "def TSS_value(num):\n",
    "  if (num <= 20.0):\n",
    "    return 1\n",
    "  elif(num <= 49.9):\n",
    "    return 3\n",
    "  elif(num <= 100):\n",
    "    return 6\n",
    "  else:\n",
    "    return 10\n",
    "\n",
    "#生化需氧量點數\n",
    "def BOD_value(num):\n",
    "  if (num <= 3.0):\n",
    "    return 1\n",
    "  elif(num <= 4.9):\n",
    "    return 3\n",
    "  elif(num <= 15.0):\n",
    "    return 6\n",
    "  else:\n",
    "    return 10\n",
    "\n",
    "#氨氣點數\n",
    "def NH3N_value(num):\n",
    "  if (num <= 0.5):\n",
    "    return 1\n",
    "  elif(num <= 0.99):\n",
    "    return 3\n",
    "  elif(num <= 3.0):\n",
    "    return 6\n",
    "  else:\n",
    "    return 10\n",
    "\n",
    "#計算RPI(River Pollution Index)\n",
    "def cal_RPI(DO, TSS, BOD, NH3N):\n",
    "  DO_num = DO_value(DO)\n",
    "  TSS_num = TSS_value(TSS)\n",
    "  BOD_num = BOD_value(BOD)\n",
    "  NH3N_num = NH3N_value(NH3N)\n",
    "  return (DO_num + TSS_num + BOD_num + NH3N_num)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe2437e-a4af-4318-96b0-dddba084cde6",
   "metadata": {
    "id": "bbe2437e-a4af-4318-96b0-dddba084cde6"
   },
   "outputs": [],
   "source": [
    "# RPI = (DO + SS + BOD + NH3N) / 4\n",
    "# NH3-N / NO3-N = K  -->  NH3-N = NO3-N * K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bc81a9-8139-4a24-9dac-3aa6b5f37255",
   "metadata": {
    "id": "68bc81a9-8139-4a24-9dac-3aa6b5f37255"
   },
   "outputs": [],
   "source": [
    "# def cal_RPI(DO, SS, BOD, NH3N):\n",
    "#     return (DO + SS + BOD + NH3N) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea27c056-bc25-4afa-97f4-a1553827c33c",
   "metadata": {
    "id": "ea27c056-bc25-4afa-97f4-a1553827c33c"
   },
   "outputs": [],
   "source": [
    "APRIL_RPI = cal_RPI(9.0 ,15, 0 ,1.3/4.5)\n",
    "MAY_RPI = cal_RPI(8.4, 10, 0, 2.5/4.5)\n",
    "JUNE_RPI = cal_RPI(8.5, 16, 0, 1.7/4.5)\n",
    "JULY_RPI = cal_RPI(6.4, 24, 0, 2.6/4.5)\n",
    "AUGUST_RPI = cal_RPI(8.1, 143, 0, 1.2/4.5)\n",
    "SEPTEMBER_RPI = cal_RPI(7.7, 53, 0, 1.5/4.5)\n",
    "OCTOBER_RPI = cal_RPI(7.8, 23, 0, 1.2 / 4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30aeb04e-2848-48be-8cf8-d089dd47956b",
   "metadata": {
    "id": "30aeb04e-2848-48be-8cf8-d089dd47956b",
    "outputId": "060f1062-58f0-4603-ab0b-fdbdbe66bf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April RPI: 1.0\n",
      "May RPI: 1.5\n",
      "June RPI: 1.0\n",
      "July RPI: 2.5\n",
      "August RPI: 3.25\n",
      "September RPI: 2.25\n",
      "October PRI: 1.5\n"
     ]
    }
   ],
   "source": [
    "# Printing the calculated values\n",
    "print(\"April RPI:\", APRIL_RPI)\n",
    "print(\"May RPI:\", MAY_RPI)\n",
    "print(\"June RPI:\", JUNE_RPI)\n",
    "print(\"July RPI:\", JULY_RPI)\n",
    "print(\"August RPI:\", AUGUST_RPI)\n",
    "print(\"September RPI:\", SEPTEMBER_RPI)\n",
    "print(\"October PRI:\", OCTOBER_RPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cee9eb-68ea-447a-b9db-3cfc0be1d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: change the label\n",
    "def get_label(val):\n",
    "    if val <= 2.0:\n",
    "        return \"NP\"\n",
    "    elif val <= 3.0:\n",
    "        return \"SP\"\n",
    "    elif val <= 6.0:\n",
    "        return \"MP\"\n",
    "    else:\n",
    "        return \"SEVERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031f260f-5929-4d6b-8e6e-adcd3699c6fa",
   "metadata": {
    "id": "031f260f-5929-4d6b-8e6e-adcd3699c6fa"
   },
   "outputs": [],
   "source": [
    "folder_paths = ['./水質檢測/Image_data/1_April',\n",
    "                './水質檢測/Image_data/2_May',\n",
    "                './水質檢測/Image_data/3_June',\n",
    "                './水質檢測/Image_data/4_July',\n",
    "                './水質檢測/Image_data/5_August',\n",
    "                './水質檢測/Image_data/6_September']\n",
    "labels = [get_label(APRIL_RPI), get_label(MAY_RPI), get_label(JUNE_RPI), \n",
    "          get_label(JULY_RPI), get_label(AUGUST_RPI), get_label(SEPTEMBER_RPI)]  # 对应文件夹1和文件夹2的标签\n",
    "\n",
    "\n",
    "oct_paths = [\"./水質檢測/Image_data/7_October\"]\n",
    "oct_label_Stirng = [get_label(OCTOBER_RPI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e666a5-c933-4693-917e-ae6851d0ab52",
   "metadata": {
    "id": "09e666a5-c933-4693-917e-ae6851d0ab52"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def load_and_label_images(folder_path, label):\n",
    "    image_paths = []  # 存储图像文件的路径\n",
    "    labels = []       # 存储图像对应的标签\n",
    "\n",
    "    # 获取文件夹中的所有图像文件的路径\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # 假设只加载jpg和png格式的图像文件\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "            labels.append(label)\n",
    "\n",
    "    # 加载图像并为其指定标签\n",
    "    images = [tf.io.read_file(image_path) for image_path in image_paths]\n",
    "    images = [tf.image.decode_image(image, channels=3) for image in images]\n",
    "\n",
    "    # 可选的数据预处理：这里假设对图像进行归一化\n",
    "    #images = [tf.cast(image, tf.float32) / 255.0 for image in images]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1275d6-df3d-4313-bc65-ea41b554f30b",
   "metadata": {
    "id": "9c1275d6-df3d-4313-bc65-ea41b554f30b"
   },
   "outputs": [],
   "source": [
    "# 你可以根据需要加载多个文件夹中的图像并为其指定不同的标签\n",
    "# folder_paths = ['/path/to/folder1', '/path/to/folder2']\n",
    "# labels = [1, 2]  # 对应文件夹1和文件夹2的标签\n",
    "\n",
    "# 加载所有文件夹中的图像和标签\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for folder_path, label in zip(folder_paths, labels):\n",
    "    images, labels = load_and_label_images(folder_path, label)\n",
    "    all_images.extend(images)\n",
    "    all_labels.extend(labels)\n",
    "    \n",
    "\n",
    "oct_images = []\n",
    "oct_labels = []\n",
    "for oct_path, label in zip(oct_paths, oct_label_Stirng):\n",
    "    images, labels = load_and_label_images(oct_path, oct_label_Stirng)\n",
    "    images_resized = [tf.image.resize(img, (224, 224)) for img  in images]\n",
    "    oct_images.extend(images_resized)\n",
    "    oct_labels.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb56706-c873-4e3e-af24-a6db9109ea4e",
   "metadata": {
    "id": "afb56706-c873-4e3e-af24-a6db9109ea4e"
   },
   "outputs": [],
   "source": [
    "# print(all_labels)\n",
    "# print(oct_labels)\n",
    "\n",
    "label_mapping = {\n",
    "    \"NP\":[1,0,0],\n",
    "    \"MP\":[0,1,0],\n",
    "    \"SP\":[0,0,1]\n",
    "}\n",
    "\n",
    "# unique_labels_list = list(set(all_labels))\n",
    "# unique_labels_list.sort()\n",
    "# label_to_index = {label: index for index, label in enumerate(unique_labels_list)}\n",
    "# label_one_hot = [tf.one_hot(label_to_index[label], len(unique_labels_list)) for label in all_labels]\n",
    "label_one_hot = [label_mapping[label] for label in all_labels]\n",
    "oct_label_one_hot = [label_mapping[label[0]] for label in oct_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f916f3f2-2c54-44fb-ab38-686d39e25d5a",
   "metadata": {
    "id": "f916f3f2-2c54-44fb-ab38-686d39e25d5a",
    "outputId": "8d52d023-5f1d-4c2c-8ab7-a31566b0a06d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9728\n",
      "(224, 224, 3)\n",
      "9728\n",
      "[[1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0]]\n",
      "=============================\n",
      "612\n",
      "(224, 224, 3)\n",
      "612\n",
      "[[1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_images))\n",
    "print(all_images[0].shape)\n",
    "print(len(label_one_hot))\n",
    "print(label_one_hot[0:10])\n",
    "\n",
    "print(\"=============================\")\n",
    "\n",
    "print(len(oct_images))\n",
    "print(oct_images[0].shape)\n",
    "print(len(oct_label_one_hot))\n",
    "print(oct_label_one_hot[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c62937c-f7ff-4f53-aa11-fe829587d15b",
   "metadata": {
    "id": "8c62937c-f7ff-4f53-aa11-fe829587d15b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_images, validation_images, train_labels, validation_labels = train_test_split(all_images, label_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 创建训练集数据集\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size=32)\n",
    "\n",
    "# # 创建验证集数据集\n",
    "# validation_dataset = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "# validation_dataset = validation_dataset.shuffle(buffer_size=len(validation_images)).batch(batch_size=32)\n",
    "\n",
    "# 創建測試資料集\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((oct_images, oct_label_one_hot))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=len(oct_images)).batch(batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a64943b7-3d2b-4b80-b0cc-e4e0db1f458e",
   "metadata": {
    "id": "a64943b7-3d2b-4b80-b0cc-e4e0db1f458e"
   },
   "outputs": [],
   "source": [
    "# # 构建数据集\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((all_images, label_one_hot))\n",
    "\n",
    "# # 可选的打乱和分批处理\n",
    "# dataset = dataset.shuffle(buffer_size=len(all_images)).batch(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee37a14c-20d5-4284-a915-218a5556fdd0",
   "metadata": {
    "id": "ee37a14c-20d5-4284-a915-218a5556fdd0",
    "outputId": "189ac0ae-1c52-4ea7-a218-08e95b8a2bc1"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 从数据集中获取并显示图像\n",
    "# fig, axs = plt.subplots(2, 5, figsize=(20, 8))  # 创建一个2x5的子图布局\n",
    "\n",
    "# for i, (image, label) in enumerate(dataset.take(10)):  # 取出前十张图像\n",
    "#     row = i // 5  # 计算当前图像应该位于的行索引\n",
    "#     col = i % 5   # 计算当前图像应该位于的列索引\n",
    "\n",
    "#     axs[row, col].imshow(image[0])  # 假设每个batch里只有一张图像\n",
    "#     axs[row, col].set_title('Label: {}'.format(label[0].numpy()))\n",
    "#     axs[row, col].axis('off')  # 关闭坐标轴\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11fadea-067a-41f5-93f3-e1dd204bbf40",
   "metadata": {
    "id": "d11fadea-067a-41f5-93f3-e1dd204bbf40"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 定义一个简单的卷积神经网络模型\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # tf.keras.layers.Dropout(0.1), \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # tf.keras.layers.Dropout(0.1),   \n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12621545-afcf-43a9-9c51-e9108a9a7451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 18.7676 - accuracy: 0.5326\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52621, saving model to best_model_fold_2.keras\n",
      "274/274 [==============================] - 373s 1s/step - loss: 18.7676 - accuracy: 0.5326 - val_loss: 0.9978 - val_accuracy: 0.5262\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 1.0854 - accuracy: 0.5432\n",
      "Epoch 2: val_accuracy improved from 0.52621 to 0.55190, saving model to best_model_fold_2.keras\n",
      "274/274 [==============================] - 369s 1s/step - loss: 1.0854 - accuracy: 0.5432 - val_loss: 0.9475 - val_accuracy: 0.5519\n",
      "31/31 [==============================] - 8s 255ms/step\n",
      "Confusion Matrix for fold 2:\n",
      "[[487   1  11]\n",
      " [171   5   2]\n",
      " [249   2  45]]\n",
      "Training fold 2...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 12.0126 - accuracy: 0.7885\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99692, saving model to best_model_fold_3.keras\n",
      "274/274 [==============================] - 393s 1s/step - loss: 12.0126 - accuracy: 0.7885 - val_loss: 0.0592 - val_accuracy: 0.9969\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9957\n",
      "Epoch 2: val_accuracy did not improve from 0.99692\n",
      "274/274 [==============================] - 393s 1s/step - loss: 0.0234 - accuracy: 0.9957 - val_loss: 0.0494 - val_accuracy: 0.9938\n",
      "31/31 [==============================] - 8s 259ms/step\n",
      "Confusion Matrix for fold 3:\n",
      "[[525   0   2]\n",
      " [  0 165   1]\n",
      " [  0   0 280]]\n",
      "Training fold 3...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 19.8638 - accuracy: 0.5840\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94245, saving model to best_model_fold_4.keras\n",
      "274/274 [==============================] - 376s 1s/step - loss: 19.8638 - accuracy: 0.5840 - val_loss: 0.2752 - val_accuracy: 0.9424\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9898\n",
      "Epoch 2: val_accuracy improved from 0.94245 to 0.99794, saving model to best_model_fold_4.keras\n",
      "274/274 [==============================] - 334s 1s/step - loss: 0.0491 - accuracy: 0.9898 - val_loss: 0.0053 - val_accuracy: 0.9979\n",
      "31/31 [==============================] - 8s 258ms/step\n",
      "Confusion Matrix for fold 4:\n",
      "[[514   0   2]\n",
      " [  0 153   0]\n",
      " [  0   0 304]]\n",
      "Training fold 4...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.3423 - accuracy: 0.7358\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99075, saving model to best_model_fold_5.keras\n",
      "274/274 [==============================] - 351s 1s/step - loss: 10.3423 - accuracy: 0.7358 - val_loss: 0.0413 - val_accuracy: 0.9908\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 2: val_accuracy improved from 0.99075 to 1.00000, saving model to best_model_fold_5.keras\n",
      "274/274 [==============================] - 310s 1s/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "31/31 [==============================] - 7s 225ms/step\n",
      "Confusion Matrix for fold 5:\n",
      "[[532   0   0]\n",
      " [  0 148   0]\n",
      " [  0   0 293]]\n",
      "Training fold 5...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 12.0111 - accuracy: 0.6827\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94142, saving model to best_model_fold_6.keras\n",
      "274/274 [==============================] - 311s 1s/step - loss: 12.0111 - accuracy: 0.6827 - val_loss: 0.2412 - val_accuracy: 0.9414\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9785\n",
      "Epoch 2: val_accuracy improved from 0.94142 to 0.99692, saving model to best_model_fold_6.keras\n",
      "274/274 [==============================] - 331s 1s/step - loss: 0.0775 - accuracy: 0.9785 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "31/31 [==============================] - 7s 227ms/step\n",
      "Confusion Matrix for fold 6:\n",
      "[[509   0   1]\n",
      " [  0 170   0]\n",
      " [  2   0 291]]\n",
      "Training fold 6...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.0250 - accuracy: 0.5573\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52621, saving model to best_model_fold_7.keras\n",
      "274/274 [==============================] - 330s 1s/step - loss: 7.0250 - accuracy: 0.5573 - val_loss: 0.9917 - val_accuracy: 0.5262\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.8652\n",
      "Epoch 2: val_accuracy improved from 0.52621 to 0.99794, saving model to best_model_fold_7.keras\n",
      "274/274 [==============================] - 336s 1s/step - loss: 0.3343 - accuracy: 0.8652 - val_loss: 0.0054 - val_accuracy: 0.9979\n",
      "31/31 [==============================] - 7s 236ms/step\n",
      "Confusion Matrix for fold 7:\n",
      "[[491   0   2]\n",
      " [  0 177   0]\n",
      " [  0   0 303]]\n",
      "Training fold 7...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 14.8299 - accuracy: 0.5429\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71942, saving model to best_model_fold_8.keras\n",
      "274/274 [==============================] - 330s 1s/step - loss: 14.8299 - accuracy: 0.5429 - val_loss: 0.6930 - val_accuracy: 0.7194\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9808\n",
      "Epoch 2: val_accuracy improved from 0.71942 to 0.99794, saving model to best_model_fold_8.keras\n",
      "274/274 [==============================] - 331s 1s/step - loss: 0.0874 - accuracy: 0.9808 - val_loss: 0.0053 - val_accuracy: 0.9979\n",
      "31/31 [==============================] - 7s 233ms/step\n",
      "Confusion Matrix for fold 8:\n",
      "[[501   0   1]\n",
      " [  0 172   0]\n",
      " [  1   0 298]]\n",
      "Training fold 8...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.2662 - accuracy: 0.5786\n",
      "Epoch 1: val_accuracy improved from -inf to 0.96197, saving model to best_model_fold_9.keras\n",
      "274/274 [==============================] - 344s 1s/step - loss: 8.2662 - accuracy: 0.5786 - val_loss: 0.2614 - val_accuracy: 0.9620\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9780\n",
      "Epoch 2: val_accuracy improved from 0.96197 to 1.00000, saving model to best_model_fold_9.keras\n",
      "274/274 [==============================] - 372s 1s/step - loss: 0.0905 - accuracy: 0.9780 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "31/31 [==============================] - 8s 249ms/step\n",
      "Confusion Matrix for fold 9:\n",
      "[[468   0   0]\n",
      " [  0 178   0]\n",
      " [  0   0 327]]\n",
      "Training fold 9...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.1896 - accuracy: 0.6670\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61934, saving model to best_model_fold_10.keras\n",
      "274/274 [==============================] - 384s 1s/step - loss: 7.1896 - accuracy: 0.6670 - val_loss: 0.8055 - val_accuracy: 0.6193\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9732\n",
      "Epoch 2: val_accuracy improved from 0.61934 to 0.99691, saving model to best_model_fold_10.keras\n",
      "274/274 [==============================] - 392s 1s/step - loss: 0.0900 - accuracy: 0.9732 - val_loss: 0.0061 - val_accuracy: 0.9969\n",
      "31/31 [==============================] - 9s 275ms/step\n",
      "Confusion Matrix for fold 10:\n",
      "[[526   1   0]\n",
      " [  0 168   0]\n",
      " [  2   0 275]]\n",
      "Training fold 10...\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.3139 - accuracy: 0.8575\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99588, saving model to best_model_fold_11.keras\n",
      "274/274 [==============================] - 364s 1s/step - loss: 7.3139 - accuracy: 0.8575 - val_loss: 0.0428 - val_accuracy: 0.9959\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9985\n",
      "Epoch 2: val_accuracy improved from 0.99588 to 0.99794, saving model to best_model_fold_11.keras\n",
      "274/274 [==============================] - 386s 1s/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0236 - val_accuracy: 0.9979\n",
      "31/31 [==============================] - 8s 245ms/step\n",
      "Confusion Matrix for fold 11:\n",
      "[[486   0   0]\n",
      " [  2 182   0]\n",
      " [  0   0 302]]\n",
      "Average Confusion Matrix:\n",
      "[[5.039e+02 2.000e-01 1.900e+00]\n",
      " [1.730e+01 1.518e+02 3.000e-01]\n",
      " [2.540e+01 2.000e-01 2.718e+02]]\n"
     ]
    }
   ],
   "source": [
    "num_fold = 10\n",
    "all_images = np.array(all_images)\n",
    "label_one_hot = np.array(label_one_hot)\n",
    "\n",
    "kf = KFold(n_splits=num_fold, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_index, val_index in kf.split(all_images):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    # print(f\"train_index={train_index}, val_index={val_index}\")\n",
    "    fold += 1\n",
    "    \n",
    "    train_images, val_images = all_images[train_index], all_images[val_index]\n",
    "    train_labels, val_labels = label_one_hot[train_index], label_one_hot[val_index]\n",
    "    \n",
    "    # 創建數據集\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(32)\n",
    "    \n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    # 創建和編譯模型\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # 訓練模型\n",
    "    model.fit(train_dataset, validation_data=val_dataset, epochs=2, callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'best_model_fold_{fold}.keras', \n",
    "                                           monitor='val_accuracy', \n",
    "                                           save_best_only=True, \n",
    "                                           mode='max', \n",
    "                                           verbose=1)\n",
    "    ])\n",
    "    \n",
    "    # 評估模型\n",
    "    model.load_weights(f'best_model_fold_{fold}.keras')\n",
    "    \n",
    "    # 使用模型預測\n",
    "    predictions = model.predict(val_dataset)\n",
    "    predicted_classes_index = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    true_classes_index = np.argmax(val_labels, axis=1)\n",
    "    \n",
    "    # 計算混淆矩陣\n",
    "    conf_matrix = confusion_matrix(true_classes_index, predicted_classes_index)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(\"Confusion Matrix for fold {}:\".format(fold))\n",
    "    print(conf_matrix)\n",
    "    model.save(f\"model_fold_{fold}.h5\")\n",
    "\n",
    "# 平均混淆矩陣\n",
    "average_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(average_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318dd38c-5f37-4242-992d-057dacd8da05",
   "metadata": {
    "id": "318dd38c-5f37-4242-992d-057dacd8da05"
   },
   "outputs": [],
   "source": [
    "# model = create_model()\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.categorical_crossentropy,\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3708dceb-452d-4180-bdef-45468222aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath='best_model.keras',  # 保存模型的文件路径\n",
    "#     monitor='val_accuracy',    # 监控的指标，可以是'val_loss'或'val_accuracy'\n",
    "#     save_best_only=True,       # 仅保存最好的模型\n",
    "#     mode='max',                # 对于准确率，使用'max'模式\n",
    "#     verbose=1                  # 输出详细日志信息\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb945a98-1fc8-4c0e-bc09-5fa2171e459d",
   "metadata": {
    "id": "bb945a98-1fc8-4c0e-bc09-5fa2171e459d",
    "outputId": "11fa26b6-c422-466a-e69f-321ed66f8461"
   },
   "outputs": [],
   "source": [
    "# 這裡建議把epoch設小一點\n",
    "# 我跑的時候差不多一個epoch要5~7分鐘\n",
    "\n",
    "# result = model.fit(train_dataset, \n",
    "#                    validation_data=validation_dataset, \n",
    "#                    epochs=5,verbose=1, \n",
    "#                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06465f2b-9774-4fc1-8257-070ecebde2b4",
   "metadata": {
    "id": "06465f2b-9774-4fc1-8257-070ecebde2b4",
    "outputId": "750dd20a-5bcd-4cab-f81d-c5fe127af6f4"
   },
   "outputs": [],
   "source": [
    "# plt.plot(result.history['accuracy'], label='accuracy')\n",
    "# plt.plot(result.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b81bd23-cd48-45a9-bdaf-a632cb19c23c",
   "metadata": {
    "id": "0b81bd23-cd48-45a9-bdaf-a632cb19c23c"
   },
   "outputs": [],
   "source": [
    "# from time import datetime\n",
    "# model_name = \"model\" + datetime.now().strftime(\"%Y-%m-%d\") + \".h5\"\n",
    "# model_name = \"model.h5\"\n",
    "# model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fd48e60-4a6e-46cb-967e-f5bdb9a610ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name=\"\"\n",
    "# model = tf.keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6aa3f-295a-4ba5-a917-3bfdaffbbc52",
   "metadata": {
    "id": "c6c6aa3f-295a-4ba5-a917-3bfdaffbbc52"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # 使用model預測\n",
    "# predictions = model.predict(test_dataset)\n",
    "# # 轉換成class index\n",
    "# predicted_classes_index = np.argmax(predictions, axis=1)\n",
    "# true_classes_index = np.argmax([label.numpy() for label in oct_label_one_hot], axis=1)\n",
    "\n",
    "# # 計算confusion matrix\n",
    "# conf_matrix = confusion_matrix(true_classes_index, predicted_classes_index)\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f39779e1-e545-4188-8b00-ef0da5e6ad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 219ms/step\n",
      "20/20 [==============================] - 4s 205ms/step\n",
      "20/20 [==============================] - 5s 232ms/step\n",
      "20/20 [==============================] - 5s 230ms/step\n",
      "20/20 [==============================] - 5s 231ms/step\n",
      "20/20 [==============================] - 4s 216ms/step\n",
      "20/20 [==============================] - 5s 239ms/step\n",
      "20/20 [==============================] - 5s 267ms/step\n",
      "20/20 [==============================] - 5s 242ms/step\n",
      "20/20 [==============================] - 5s 265ms/step\n"
     ]
    }
   ],
   "source": [
    "all_test_predictions = []\n",
    "\n",
    "for fold in range(2, num_fold+2):\n",
    "    model_name=f\"model_fold_{fold}.h5\"\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    fold_predictions = model.predict(test_dataset)\n",
    "    all_test_predictions.append(fold_predictions)\n",
    "    \n",
    "average_test_predictions = np.mean(all_test_predictions, axis=0)\n",
    "predicted_classes_index = np.argmax(average_test_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a15c65ea-e819-49ab-9ca3-913787e56f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[611   0   1]\n",
      " [  0   0   0]\n",
      " [  0   0   0]]\n",
      "Accuracy: 0.9983660130718954\n"
     ]
    }
   ],
   "source": [
    "# 所有模型的預測結果的平均\n",
    "\n",
    "\n",
    "\n",
    "true_classes_index = np.argmax([np.array(label) for label in oct_label_one_hot], axis=1)\n",
    "# print(true_classes_index)\n",
    "\n",
    "# print(f\"({len(all_test_predictions)}, {len(all_test_predictions[0])}, {len(all_test_predictions[0][0])})\")\n",
    "# print(average_test_predictions.shape)\n",
    "# print(predicted_classes_index.shape)\n",
    "# print(average_test_predictions)\n",
    "\n",
    "# # 計算confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes_index, predicted_classes_index, labels=np.arange(3))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(true_classes_index, predicted_classes_index)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iv_0o-93lQra",
   "metadata": {
    "id": "iv_0o-93lQra"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# predictions = np.array(predictions)\n",
    "# true_labels = np.array(oct_label_one_hot)\n",
    "# print(predictions.shape, true_labels.shape)\n",
    "\n",
    "# # 計算AUCROC\n",
    "# aucroc = roc_auc_score(true_labels, predictions, average='macro', multi_class='ovo')\n",
    "# print(\"AUCROC:\", aucroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fada5d-efcd-40bc-80b3-ea3985ad6397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35fcf9-11b9-4a00-8fb2-d71debaa2758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
