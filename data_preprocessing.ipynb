{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe2437e-a4af-4318-96b0-dddba084cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPI = (DO + SS + BOD + NH3N) / 4\n",
    "# NH3-N / NO3-N = K  -->  NH3-N = NO3-N * K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68bc81a9-8139-4a24-9dac-3aa6b5f37255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_RPI(DO, SS, BOD, NH3N):\n",
    "    return (DO + SS + BOD + NH3N) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea27c056-bc25-4afa-97f4-a1553827c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "APRIL_RPI = cal_RPI(9.0, 15, 0, 1.3 * 3)\n",
    "MAY_RPI = cal_RPI(8.4, 10, 0, 2.5 * 3.6)\n",
    "JUNE_RPI = cal_RPI(8.5, 16, 0, 1.7 * 2)\n",
    "JULY_RPI = cal_RPI(6.4, 24, 0, 2.6 * 2.3)\n",
    "AUGUST_RPI = cal_RPI(8.1, 143, 0, 1.2 * 2.6)\n",
    "SEPTEMBER_RPI = cal_RPI(7.7, 53, 0, 1.5 * 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "031f260f-5929-4d6b-8e6e-adcd3699c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = ['./水質檢測/Image_data/1_April', \n",
    "                './水質檢測/Image_data/2_May',\n",
    "                './水質檢測/Image_data/3_June',\n",
    "                './水質檢測/Image_data/4_July',\n",
    "                './水質檢測/Image_data/5_August',\n",
    "                './水質檢測/Image_data/6_September']\n",
    "labels = [APRIL_RPI, MAY_RPI, JUNE_RPI, JULY_RPI, AUGUST_RPI, SEPTEMBER_RPI]  # 对应文件夹1和文件夹2的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30aeb04e-2848-48be-8cf8-d089dd47956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April RPI: 6.975\n",
      "May RPI: 6.85\n",
      "June RPI: 6.975\n",
      "July RPI: 9.094999999999999\n",
      "August RPI: 38.555\n",
      "September RPI: 16.075\n"
     ]
    }
   ],
   "source": [
    "# Printing the calculated values\n",
    "print(\"April RPI:\", APRIL_RPI)\n",
    "print(\"May RPI:\", MAY_RPI)\n",
    "print(\"June RPI:\", JUNE_RPI)\n",
    "print(\"July RPI:\", JULY_RPI)\n",
    "print(\"August RPI:\", AUGUST_RPI)\n",
    "print(\"September RPI:\", SEPTEMBER_RPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9176cd-5f1f-4166-b95a-c11a3117baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have 2 value equal to 6.975.\n",
    "# We should use 5 label to classify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e666a5-c933-4693-917e-ae6851d0ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 09:35:50.205782: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2024-05-03 09:35:50.205797: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-05-03 09:35:50.205803: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-05-03 09:35:50.205849: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-03 09:35:50.206060: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def load_and_label_images(folder_path, label):\n",
    "    image_paths = []  # 存储图像文件的路径\n",
    "    labels = []       # 存储图像对应的标签\n",
    "\n",
    "    # 获取文件夹中的所有图像文件的路径\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # 假设只加载jpg和png格式的图像文件\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "            labels.append(label)\n",
    "\n",
    "    # 加载图像并为其指定标签\n",
    "    images = [tf.io.read_file(image_path) for image_path in image_paths]\n",
    "    images = [tf.image.decode_image(image, channels=3) for image in images]\n",
    "\n",
    "    # 可选的数据预处理：这里假设对图像进行归一化\n",
    "    images = [tf.cast(image, tf.float32) / 255.0 for image in images]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# 你可以根据需要加载多个文件夹中的图像并为其指定不同的标签\n",
    "# folder_paths = ['/path/to/folder1', '/path/to/folder2']\n",
    "# labels = [1, 2]  # 对应文件夹1和文件夹2的标签\n",
    "\n",
    "# 加载所有文件夹中的图像和标签\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for folder_path, label in zip(folder_paths, labels):\n",
    "    images, labels = load_and_label_images(folder_path, label)\n",
    "    all_images.extend(images)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# 构建数据集\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "\n",
    "# 可选的打乱和分批处理\n",
    "dataset = dataset.shuffle(buffer_size=len(all_images)).batch(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee37a14c-20d5-4284-a915-218a5556fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 从数据集中获取并显示图像\n",
    "# fig, axs = plt.subplots(2, 5, figsize=(20, 8))  # 创建一个2x5的子图布局\n",
    "\n",
    "# for i, (image, label) in enumerate(dataset.take(10)):  # 取出前十张图像\n",
    "#     row = i // 5  # 计算当前图像应该位于的行索引\n",
    "#     col = i % 5   # 计算当前图像应该位于的列索引\n",
    "    \n",
    "#     axs[row, col].imshow(image[0])  # 假设每个batch里只有一张图像\n",
    "#     axs[row, col].set_title('Label: {}'.format(label[0].numpy()))\n",
    "#     axs[row, col].axis('off')  # 关闭坐标轴\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d11fadea-067a-41f5-93f3-e1dd204bbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 定义一个简单的卷积神经网络模型\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(5, activation='softmax') \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "318dd38c-5f37-4242-992d-057dacd8da05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0xe6c0d0670>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb945a98-1fc8-4c0e-bc09-5fa2171e459d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
